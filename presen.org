#+TITLE:  ニューロシンボリック Classical Planning
#+include: "head.org"
#+LINK: img file:img/%s
#+LINK: png file:img/%s.png
#+LINK: jpg file:img/%s.jpg
#+LINK: svg file:img/%s.svg
#+LINK: gif file:img/%s.gif
#+LINK: spng file:img/static/%s.png
#+LINK: sjpg file:img/static/%s.jpg
#+html_head: <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:500,900">
#+html_head_extra:
#+LINK: ssvg file:img/static/%s.svg
#+LINK: sgif file:img/static/%s.gif

#+begin_outline-text-1
#+begin_center



#+begin_larger
Masataro Asai

(MIT-IBM Watson AI Lab, IBM Research, Cambridge)
#+end_larger



[[png:MIT-IBM]]

# [[spng:ibm-research]]

#+end_center

#+begin_center
質問はZoomに書き込み
#+end_center

#+end_outline-text-1

* Part 1:

#+begin_xlarge
#+begin_center
記号接地と

グラフィカルモデル
#+end_center
#+end_xlarge

* 火星に取り残された! うわ やっべ どうしよう?

[[png:mars/mars]]

* どっちの「知性」がいいですか?

#+begin_container-fluid
#+begin_row-fluid
#+begin_span3

[[png:mars/mars]]

#+end_span3
#+begin_span4
#+begin_center
*経験に基づく勘だけ* でどうにかなる?

"考えるな、感じろ" でうまく行きますか?

[[sgif:yoda]]

/Reflex (反射) agent/

#+end_center
#+end_span4
#+begin_span5
+
  #+begin_center
  ちょっと *頭を使って* 臨機応変に対応しますか?

  [[sgif:mars/yoda-hmph]]

  _/Deliberative (熟考) agent/_
  #+end_center
#+end_span5
#+end_row-fluid
#+end_container-fluid

#+begin_center
+ → _私がやりたいのは *熟考エージェント*_

  しかも、 _生のセンサー入力(画像)を直接使えるやつ_
#+end_center

* 古典プランナ (古典自動計画ソルバ): @@html:<br>@@ *8パズルをミリ秒単位で解ける.*

記号的探索・推論システムは爆速

#+begin_container-fluid
#+begin_row-fluid
#+begin_span2

#+end_span2
#+begin_span4
[[png:8puzzle-standard]]
#+end_span4
#+begin_span4
[[png:8puzzle-standard-goal]]
#+end_span4
#+begin_span2
[[sgif:8puzzle]]
#+end_span2
#+end_row-fluid
#+end_container-fluid

/でも PDDL があるときにしか 適用不可能./

#+begin_container-fluid
#+begin_row-fluid
#+begin_span12
#+begin_src scheme
(:action       move-up ...
 :precondition (and      (empty ?x ?y-old) ...)
 :effects      (and (not (empty ?x ?y-old))...))
#+end_src
#+end_span12
#+end_row-fluid
#+end_container-fluid

PDDL : Planning Domain Description Language

* 弱点: */画像ベース入力/* になると適用不可能

#+begin_container-fluid
#+begin_row-fluid
#+begin_span8
[[sjpg:puzzle]]
#+end_span8
#+begin_span4
+
   #+begin_center
   *なぜなら*

   *プランナは*

   *実行するのに*

   #+begin_larger
   */PDDL/*

   */モデルが/*

   */必要/!*
   #+end_larger
#+end_center
#+end_span4
#+end_row-fluid
#+end_container-fluid

+ *Latplan (AAAI18, ICAPS19, IJCAI20, JAIR 22)* はこの問題を解決

  */画像に対する事前知識なし/* (画像に対するアノテーションなど)

  　 */人に由来するラベル・記号は一切なし/* : "タイルが9つある", "動く"

* Latplan の目標: */知識獲得ボトルネックの解消/*

# * We must *automate 2 processes*:

# * Knowledge-Acquisition Bottleneck:
#
# #+begin_quote
# The *cost of human* involved for converting *real-world problems* into the inputs for
# domain-independent *symbolic* systems
# #+end_quote



#+begin_container-fluid
#+begin_row-fluid
#+begin_span4

#+begin_alignright
*状態遷移の観測データ*
#+end_alignright

[[png:overview/1]]

#+end_span4
#+begin_span1






→


#+end_span1
#+begin_span7
#+begin_center
*PDDL Model*
#+end_center
#+begin_src scheme
(:action       move-up
 :precondition
 (and      (empty ?x ?y-old) ...)
 :effects
 (and (not (empty ?x ?y-old))...))
#+end_src

#+end_span7
#+end_row-fluid

#+begin_row-fluid
#+begin_span12
+ Latplan が自動化すべき作業は *2つ* あり、これらは別のタスク:
#+end_span12
#+end_row-fluid
#+begin_row-fluid
#+begin_span6
+ *1. 記号生成:*

  #+begin_center
  #+begin_larger
  */シンボル/ = PDDL内で使われる語彙*
  #+end_larger
  #+end_center

+
  #+begin_smaller
  | Types        | Examples                     |
  |--------------+------------------------------|
  | オブジェクト | *panel_7*, *x_0*, *y_0* ...  |
  | 述語 | (*empty* ?x ?y)              |
  | 命題 | *p_28* = (empty x_0 y_0)     |
  | アクション | (*slide-up* panel_7 x_0 y_1) |
  #+end_smaller
#+end_span6
#+begin_span6
+ *2. アクションモデル獲得:*

  #+begin_center
  #+begin_larger
  */状態遷移ルールを/*

  */シンボルを用いて/*

  */表現すること/*
  #+end_larger
  #+end_center

+

  #+begin_center
  *When* /Empty(x, y_{old}) ∧ .../ ;

  *Then* /¬Empty(x,y_{old}) ∧/ ...
  #+end_center

#+end_span6
#+end_row-fluid
#+end_container-fluid

# #+begin_note
# The knowledge acquisition bottleneck: time for reassessment? : Cullen, J and Bryman, A Expert Syst. Vol 5 No 3 (August 1988) pp 216-225
# #+end_note

* Latplan は PDDL を自動生成 (IJCAI20, JAIR22)

[[png:15puzzle-with-pddl/2]]

　

　

　

　

** Latplan は PDDL を自動生成 (IJCAI20, JAIR22)

[[png:15puzzle-with-pddl/1]]

　

　

　

　

** Latplan は PDDL を自動生成 (IJCAI20, JAIR22)

[[png:15puzzle-with-pddl/0]]

#+begin_center
+ Latplan が生成・接地するシンボルは すべて *無名シンボル* (=gensym=)

  *人間の使う 自然言語シンボル* は扱わない

+ 自然言語シンボルへの接地は *寄生的* 記号接地(*) とよばれる

  *理由:* 人間の作った世界の離散化に依存しているから (例: *虹🌈は7色?*)

  #+begin_note
  (*) Taddeo, Mariarosaria, and Luciano Floridi. "Solving the symbol grounding problem: a critical review of fifteen years of research." Journal of Experimental & Theoretical Artificial Intelligence 17.4 (2005): 419-445.
  #+end_note
#+end_center


* Latplan が解けるパズル/プランニング問題の例

[[spng:experiment/init-goal]]

8-puzzle, 15-puzzle, Lights-Out, Twisted Lights-out, *Blocksworld*, Sokoban

** 成功率 (1ドメインあたり40タスク)

[[png:success]]

** 成功例 / 失敗例

[[spng:experiment/blocks-example]]

# [[spng:experiment/other-examples]]

* このシステムの肝: *生成モデリング* + @@html:<br>@@ _/ちゃんと古典プランニングのことを勉強すること/_

+ Latplan は *PDDLと互換性のあるアクションモデルを画像から学習する*.
+ *「PDDLと互換性がある」ってどういう意味 ?*

# *Background Terminology:*
#
# $z_{t} \rightarrow z_{t+1}$ is called a /progression/
# #+begin_alignright
# ($z_{t+1} \rightarrow z_{t}$ is called a /regression/)
# #+end_alignright

+ アクション: $a=\text{Eat}(\text{pizza🍕})$
+ 前提条件: $\text{pre}(a)=\lnot \text{full}() \land \text{have}(\text{pizza🍕})$ --- 空腹かつピザがある
+ 効果: *削除効果:* $\text{del}(a)=\{\text{have}(\text{pizza🍕}) \}$ --- ピザはなくなって
+ 効果: *追加効果:* $\text{add}(a)=\{\text{full}() \}$ --- 満腹になる

# + Action /eat(person, pizza)/
# + Precondition: ¬full(person) ∧ have(person, pizza)
# + Delete effect: ¬have(person, pizza)
# + Add effect: full(person)

# +
#   #+begin_src scheme
#   (:action eat :parameters (?person ?pizza)
#   #+end_src
# +
#   #+begin_src scheme
#   　 :precondition (and (not (full ?person))
#   　                   (have ?person ?pizza))
#   #+end_src
# +
#   #+begin_src scheme
#   　 :effects (and (not (have ?person ?pizza)) ; delete effects
#   　               (full ?person)))           ; add effects
#   #+end_src

+
  #+begin_quote
  _/状態遷移ルール:/_ $z_{t+1} = (z_t \setminus \text{del}(a)\ )\ \cup\ \text{add}(a)$
  #+end_quote

  効果 $\text{del}(a), \text{add}(a)$ は *$z_t$ に依存しない*.

+ */よくある世界モデル/* は *そこをわかってない！* (自動計画の人がいない)
  #+begin_quote
  */よくある世界モデル:/* $z_{t+1} = \text{なぞのニューラルネット}(z_t, a)$
  #+end_quote

+

  #+begin_larger
  #+begin_center
  PDDLに変換できない → */高速なソルバを使えない/*
  #+end_center
  #+end_larger


# +
#   #+begin_quote
#   _/PDDL effect:/_ $z_{t+1} = (z_t \ \setminus \ \text{del}(a)\ )\ \cup\ \text{add}(a)$
#
#   */AAE's effect:/* $z_{t+1} = \text{apply}(z_t, a)$
#   #+end_quote
#
#   *In PDDL, effects should be consistent for each action*.
#
#   #+begin_alignright
#   *= Effects should be independent from $z_t$*
#   #+end_alignright

* 高速ソルバのためにPDDL記号モデルを学習 @@html:<br>@@ →言語の制約を */NNモデルに埋め込まないといけない/*

+ *PDDLでは、アクションの効果と状態 $z_t$ は独立している.*

#+begin_center
+ → $z_t$ と独立な変数 *e* を導入する必要あり。

+ 　
  
  [[png:space-ae/graphical-model-csae]]
#+end_center

# #+begin_smaller
# 無名シンボルを生成するため、$z_t$ や $a$ には *離散隠れ変数* を使う (Gumbel-Softmax)
# #+end_smaller

+ これを *離散的隠れ変数* (Gumbel-Softmax) + *変分学習* で訓練。

  グラフィカルモデルが数学的根拠を与える

* 離散表現学習: Gumbel-Softmax VAE ほか

[[png:sae/state-ae-before]]

** 離散表現学習: Gumbel-Softmax VAE ほか

[[png:sae/state-ae]]

+ 2017年ぐらい以降、多数の手法が考案されている

  (REBAR, RELAX, VQVAE, SQVAE, ...)

  +
    #+begin_alignright
    ニューロシンボリックをするなら要チェック!
    #+end_alignright

* Important aspects of symbol grounding:                           :noexport:

Definition of symbol: *not* just state variables.

*Symbol* : A structure containing a pointer to a /name/ and a pointer to an /object/.

#+begin_container-fluid
#+begin_row-fluid
#+begin_span4
#+begin_src lisp
(defstruct symbol
  name
  object)
#+end_src
#+end_span4
#+begin_span4
#+begin_src python
class Symbol:
  name: string,
  obj: Any
#+end_src
#+end_span4
#+begin_span4
#+begin_src C
struct symbol {
    void* name;
    void* object;
}
#+end_src
#+end_span4
#+end_row-fluid
#+end_container-fluid

A symbol may point to *various things* through a hash table.

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
#+begin_src lisp
(symbol-value    'my-variable)
(symbol-function 'my-function)
(make-instance   'my-class)
#+end_src
#+end_span6
#+begin_span6
#+begin_src python
function_dictionary["myfunc"]
function_dictionary["myfunc"]
#+end_src
#+end_span6
#+end_row-fluid
#+end_container-fluid

* /シンボル/ は一種類だけではない

*/命題シンボル/* (handempty, ...) vs. _/アクションシンボル/_ (pickup,...).

#+begin_container-fluid
#+begin_row-fluid
#+begin_span4
[[png:space-ae/graphical-model-csae-only]]
#+end_span4
#+begin_span8
#+begin_center
+
  #+begin_larger
  これらは *別の名前空間に存在する*.
  #+end_larger

  　

  自然言語シンボルも同様:

  　 I */like/* an apple : 動詞

  　 Thanks for the */like/* on Facebook! : 名詞

  Common Lisp (Lisp-2) vs. Scheme (Lisp-1)
#+end_center

#+begin_larger
#+begin_alignright
+ → *別の名前空間* にあるシンボルは

  *別の言語制約が必要。*
#+end_alignright
#+end_larger
#+end_span8
#+end_row-fluid
#+end_container-fluid

* PDDL: 6つの名前空間, 6つのメカニズム

[[png:namespace/1]]

　

　

　

　

** PDDL: 6つの名前空間, 6つのメカニズム

[[png:namespace/2]]

　

　

　

　

** PDDL: 6つの名前空間, 6つのメカニズム

[[png:namespace/3]]

　

　

　

　

** PDDL: 6つの名前空間, 6つのメカニズム

[[png:namespace/4]]

*問題シンボル:* 「マリオのステージを表すシンボル」→ 別の状態空間を生成

　Stage 1-1, Stage 1-2, ...

　

　

** PDDL: 6つの名前空間, 6つのメカニズム

[[png:namespace/5]]

*問題シンボル:* 「マリオのステージを表すシンボル」→ 別の状態空間を生成

　Stage 1-1, Stage 1-2, ...

*ドメインシンボル:* 「別のゲームを表すシンボル」 → 別のアクションを生成

　マリオ、ゼルダ、ドンキーコング、F-Zero ...

** PDDL: 6つの名前空間, 6つのメカニズム

[[png:namespace/6]]

*問題シンボル:* 「マリオのステージを表すシンボル」→ 別の状態空間を生成

　Stage 1-1, Stage 1-2, ...

*ドメインシンボル:* 「別のゲームを表すシンボル」 → 別のアクションを生成

　マリオ、ゼルダ、ドンキーコング、F-Zero ...


* 実際 Latplan を述語論理に拡張可 (ICLR2021 workshop)

*Latplan/FOSAE++* : 画像内の異なるオブジェクトに使えるアクションを学習

#+begin_container-fluid
#+begin_row-fluid
#+begin_span4
[[png:graphical-model-fosae++-nopatch2]]
#+end_span4
#+begin_span8
[[png:blocks-wide]]
#+end_span8
#+end_row-fluid
#+end_container-fluid


+ *追加制約:* Successor State Axiom (*非束縛変数の禁止* [Reiter, 1991])

+ アクション: $a=\text{Eat}(\text{pizza}🍕)$ : 引数 $\text{pizza}🍕$
+
  #+begin_center
  *効果:* */発表(フロム, アーマードコアの新作)/*
  #+end_center
+
  #+begin_alignright
  ↑ $\text{pizza}🍕$ を使わないので禁止
  #+end_alignright

+
  #+begin_larger
  #+begin_center
  新たな制約が *述語シンボル* のグラウンディングを可能にした
  #+end_center
  #+end_larger


* 結論                                                             :noexport:

#+begin_xlarge
記号接地したいなら

#+begin_center
*対象言語を /ちゃんと/ 理解して*
#+end_center

#+begin_alignright
*/正しい/ モデルをつくろう!*
#+end_alignright
#+end_xlarge




* 記号的言語に接地したいなら、対象言語をちゃんと理解して */正しい/* モデルをつくりましょう :noexport:

例1:
#+begin_center
画像入力 → PDDL → 高速PDDLソルバ
#+end_center

例2 (未発表):
#+begin_center
+ 非線形状態遷移モデル → 線形隠れ制御モデル → 高速線形制御ソルバ
#+end_center

[[png:space-ae/graphical-model-style]]

#+begin_center
+ *Caution: It requires a /deep/ understanding of your formalism*

  *(e.g., PDDL, linear control).* Know what you are modeling!
#+end_center

* Extending the generative model (unpublished)

#+begin_container-fluid
#+begin_row-fluid
#+begin_span4
#+begin_center
+ Lifted actions,

  Parameters *x*

  [[png:space-ae/graphical-model-fosae]]

  Predicates, too.

  *Compatible with First Order Logic.*

#+end_center
#+end_span4
#+begin_span4
#+begin_center
+ Temporal actions,

  Action durations *d*

  [[png:space-ae/graphical-model-time]]

  *Compatible with LTL.*

#+end_center
#+end_span4
#+begin_span4
#+begin_center
+ Domain symbol *D*,

  Problem symbol *P*

  [[png:space-ae/graphical-model-domain]]

  Allows mixed-domain training?
#+end_center
#+end_span4
#+end_row-fluid
#+end_container-fluid

# + Discrete-Continuous
#
#  [[png:space-ae/graphical-model-style]]



* Part 1: Conclusion

#+begin_container-fluid
#+begin_row-fluid
#+begin_span7
#+begin_center
+ *Goal: 理性的な実世界エージェント*

  [[sgif:mars/yoda-hmph]]
#+end_center
#+end_span7
#+begin_span5
#+begin_center
+ *Latplan* で記号接地

  [[sjpg:puzzle]]

#+end_center
#+end_span5
#+end_row-fluid
#+begin_row-fluid
#+begin_span7
#+begin_center
+ 異なるシンボルは  *別々の制約が必要*

  [[png:namespace/6]]
#+end_center
#+end_span7
#+begin_span5
#+begin_center
+ 生成モデルによって

  *制約を精緻に記述可能*

  [[png:space-ae/graphical-model-csae]]
#+end_center
#+end_span5
#+end_row-fluid
#+end_container-fluid

# #+begin_center
# Masataro Asai, Hiroshi Kajino, Alex Fukunaga, Christian Muise:
#
# *Classical Planning in Deep Latent Space.* Arxiv 2107.00110 -> JAIR
# #+end_center

+ 記号接地するなら *対象言語を /ちゃんと/ 理解して /正しく/ モデル化しよう!*


#+begin_center
質問: 2つまで
#+end_center

* Why _/action symbol grounding/_ is necessary?                    :noexport:

"designers always know the action space"? */Wrong!/*

Humans have a good understanding of low-level actuations...

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
+
  #+begin_center
  Running
  #+end_center
  [[sjpg:triathlon/running]]
# sjpg:triathlon/bicycle
# sjpg:triathlon/swimming
#+end_span6
#+begin_span6
+
  #+begin_center
  Career Path
  #+end_center
  [[sjpg:triathlon/career]]

  #+begin_center
  Do you fully understand all of your opportunities?
  #+end_center
#+end_span6
#+end_row-fluid
#+begin_row-fluid
#+begin_span6
#+begin_center
+ *Low-level Control*
#+end_center
#+end_span6
#+begin_span6
#+begin_center
+ */High-level Action/*
#+end_center
#+end_span6
#+end_row-fluid
#+end_container-fluid



* Part 2:

#+begin_xlarge
理性的な実世界エージェントの
#+begin_center
*/アーキテクチャ/*
#+end_center
#+begin_alignright
を考える
#+end_alignright
#+end_xlarge

#+begin_alignright
+ → *表現学習以外* の プランニング+機械学習
#+end_alignright


* 理性的な実世界エージェントのアーキテクチャ

#+begin_container-fluid
#+begin_row-fluid
#+begin_span3
[[sgif:mars/yoda-hmph]]
#+end_span3
#+begin_span9
[[png:nesyarch/6]]
#+end_span9
#+end_row-fluid
#+end_container-fluid

** 理性的な実世界エージェントのアーキテクチャ

#+begin_container-fluid
#+begin_row-fluid
#+begin_span3
[[sgif:mars/yoda-hmph]]
#+end_span3
#+begin_span9
[[png:nesyarch/5]]
#+end_span9
#+end_row-fluid
#+end_container-fluid

** 理性的な実世界エージェントのアーキテクチャ

#+begin_container-fluid
#+begin_row-fluid
#+begin_span3
[[sgif:mars/yoda-hmph]]
#+end_span3
#+begin_span9
[[png:nesyarch/4]]
#+end_span9
#+end_row-fluid
#+end_container-fluid

** 理性的な実世界エージェントのアーキテクチャ

#+begin_container-fluid
#+begin_row-fluid
#+begin_span3
[[sgif:mars/yoda-hmph]]
#+end_span3
#+begin_span9
[[png:nesyarch/3]]
#+end_span9
#+end_row-fluid
#+end_container-fluid

** 理性的な実世界エージェントのアーキテクチャ

#+begin_container-fluid
#+begin_row-fluid
#+begin_span3
[[sgif:mars/yoda-hmph]]
#+end_span3
#+begin_span9
[[png:nesyarch/2]]
#+end_span9
#+end_row-fluid
#+end_container-fluid

** 理性的な実世界エージェントのアーキテクチャ

#+begin_container-fluid
#+begin_row-fluid
#+begin_span3
[[sgif:mars/yoda-hmph]]
#+end_span3
#+begin_span9
[[png:nesyarch/1]]
#+end_span9
#+end_row-fluid
#+end_container-fluid

** 理性的な実世界エージェントのアーキテクチャ

#+begin_container-fluid
#+begin_row-fluid
#+begin_span3
[[sgif:mars/yoda-hmph]]
#+end_span3
#+begin_span9
[[png:nesyarch/0]]
#+end_span9
#+end_row-fluid
#+end_container-fluid

** 理性的な実世界エージェントのアーキテクチャ

#+begin_container-fluid
#+begin_row-fluid
#+begin_span3
[[sgif:mars/yoda-hmph]]
#+end_span3
#+begin_span9
[[png:nesyarch/0a]]
#+end_span9
#+end_row-fluid
#+end_container-fluid

* 探索ヒューリスティクスの学習:

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
#+begin_xlarge
#+begin_center
RL

(ICAPS 2022)
#+end_center
#+end_xlarge
#+end_span6
#+begin_span6
#+begin_xlarge
#+begin_center
SL

(IJCAI 2024)
#+end_center
#+end_xlarge
#+end_span6
#+end_row-fluid
#+end_container-fluid

* ICAPS22

[[png:pddlrl/title]]

* Value function learning

SGD Loss function:

\[
\frac{1}{|B|}\sum_{s\in B} \frac{1}{2}\left| V(s) - \mathbb{E}_{a\in A} [Q(a, s)] \right|^2
\]

$B$: batches in the experience replay

#+begin_larger
Research Questions:
#+begin_center
+ *Q: RLだけで 古典プランニングを解けるか?* (A: *不可*)

+ *Q: RLだけで プランニングを高速化できるか?* (A: *不可*)

+ *Q: プランニングの道具と適切に組み合わせれば?* */(A: 可)/*
#+end_center
#+begin_alignright
+ Lessons learned: *古典プランニングを甘く見るな*
#+end_alignright
#+end_larger


* Why Classical Plannning is difficult for RL?

Rewards in Classical Planning:

#+begin_center
#+begin_larger
+ $r(s,a,s') = \left\{\begin{array}{ll} 1 & \text{if}\ s' \ \text{is a goal}, \\ 0 & \text{otherwise}. \end{array}\right.$

  *This is extremely sparse.*

#+end_larger
#+end_center

+ */Any non-goal states/* are *equally /worthless/*

  + *No guidance* for RL until a goal,

  + which is *difficult to find* in the first place!

* Potential-Based */Reward Shaping/* (PBRS) @@html:<br>@@ for Sparse Rewards

Given a *potential function* $\phi(s)$, */redefine rewards/* as:

\begin{align}
\hat{r}(s, a, s') &= r(s, a, s') + \gamma \phi(s') - \phi(s). \label{eq:shaping1}
\end{align}

+ */Important:/* PBRS *preserves* the optimal value function

  \begin{align}
  V^*_\gamma(s) &= \hat{V}^*_\gamma(s) + \phi(s). \label{eq:shaping2}
  \end{align}

  #+begin_alignright
  #+begin_larger
  = *learning the residual from $\phi(s)$*
  #+end_larger
  #+end_alignright

#+begin_note
Ng, Harada, Russell. "Policy invariance under reward transformations: Theory and application to reward shaping." ICML. Vol. 99. 1999.
#+end_note

* Heuristic Function $h(s)$ in classical planning

+ *Distance estimate*
  + $h(s)=5 \quad \longleftrightarrow \quad s - s_1 - s_2 - s_3 - s_4 - \text{goal}$ (おおよそ) 
  + Many implementations: $h^{\text{add}}$, $h^{\text{FF}}$, $h^{\text{CEA}}$, ...

    #+begin_smaller
    (Bonet&Geffner 01, Hoffmann 01, Helmert 08) もっと新しいのもある
    #+end_smaller

#+begin_xlarge
+ *Heuristics satisfies the PBRS requirements*

+ 
  #+begin_alignright
  */Let's use $h(s)$ for PBRS!/*
  #+end_alignright
#+end_xlarge

* Issue 1: */Discounting/*

#+begin_larger
*RL : /discounted rewards/* ↔ *Planning :* _/undiscounted costs/_
#+end_larger

　

Our solution:

+ *Training* : Convert $h(s)\rightarrow h_{\gamma}(s)$ : */discounting/* $h(s)$ for PBRS

+
  \begin{align}
  \phi(s) &= h_\gamma(s) = \sum_{t=1}^{h(s)} \gamma^t\cdot 1 = \dfrac{1 - \gamma^{h(s)}}{1 - \gamma}.
  \end{align}

  # V_\gamma(s) &= \hat{V}_\gamma(s) + \phi(s) \quad \text{where}\\
  # \phi(s) &= \sum_{t=1}^{h(s)} \gamma^t\cdot (-1) = -\frac{1-\gamma^{h(s)}}{1-\gamma}
  # h(s) &= \sum_{t=1}^{h(s)} 1, & h_\gamma(s) &= \sum_{t=1}^{h(s)} \gamma^t\cdot 1 = \dfrac{1 - \gamma^{h(s)}}{1 - \gamma}.


+ *Planning* : Convert $V_{\gamma}(s)\rightarrow V(s)$ : _/undiscounting/_ a learned $V_{\gamma}(s)$

+   
  \begin{align}
  V_\gamma(s) = \dfrac{1 - \gamma^{V(s)}}{1 - \gamma}
  &\Leftrightarrow
  V(s) = \log_\gamma (1 - (1 - \gamma)V_\gamma(s)).
  \end{align}

* Issue 2: Handling */First-Order Logic Input/*

Our solution: *Neural Logic Machine (NLM)* [Dong et. al. ICLR 2019]

[[png:pddlrl/nlm6]]

** Issue 2: Handling */First-Order Logic Input/*

Our solution: *Neural Logic Machine (NLM)* [Dong et. al. ICLR 2019]

[[png:pddlrl/nlm5]]

** Issue 2: Handling */First-Order Logic Input/*

Our solution: *Neural Logic Machine (NLM)* [Dong et. al. ICLR 2019]

[[png:pddlrl/nlm4]]

** Issue 2: Handling */First-Order Logic Input/*

Our solution: *Neural Logic Machine (NLM)* [Dong et. al. ICLR 2019]

[[png:pddlrl/nlm3]]

** Issue 2: Handling */First-Order Logic Input/*

Our solution: *Neural Logic Machine (NLM)* [Dong et. al. ICLR 2019]

[[png:pddlrl/nlm2]]

** Issue 2: Handling */First-Order Logic Input/*

Our solution: *Neural Logic Machine (NLM)* [Dong et. al. ICLR 2019]

[[png:pddlrl/nlm1]]

** Issue 2: Handling */First-Order Logic Input/*

Our solution: *Neural Logic Machine (NLM)* [Dong et. al. ICLR 2019]

[[png:pddlrl/nlm]]

+ *Size* & *Permutation invariant* to FOL binary inputs

+ *Quite useful for various FOL tasks*
  + ILP [Dong et. al. ICLR 2019]
  + Regression (our work) 

* Results

Skipped

* ICAPS 2022 : Conclusion

#+begin_center
#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
+ *Sparse Rewards*

  #+begin_smaller
  $r(s) = \left\{\begin{array}{ll} 1 & \text{if}\ s \ \text{is a goal}, \\ 0 & \text{otherwise}. \end{array}\right.$

  ゴールにたどり着くのが

  とても難しい
  #+end_smaller
#+end_span6
#+begin_span6
+ *Potential-Based*

  *Reward Shaping*

  $V^*_\gamma(s) = \hat{V}^*_\gamma(s) + \phi(s)$

  #+begin_smaller
  $\phi(s)=$ 距離の見積もり $h(s)$

  Sparse Reward を解決
  #+end_smaller
#+end_span6
#+end_row-fluid
#+begin_row-fluid
#+begin_span6
+ *Discounting*

  $h_\gamma(s)  = \dfrac{1 - \gamma^{h(s)}}{1 - \gamma}$

  $V(s) = \log_\gamma (1 - (1 - \gamma)V_\gamma(s))$

  #+begin_smaller
  これがないと

  $h(s)=\infty$ のとき死ぬ
  #+end_smaller
#+end_span6
#+begin_span6
+ *First-Order Logic Input*

  [[png:pddlrl/nlm]]

  #+begin_smaller
  異なるサイズの問題に汎化
  #+end_smaller

#+end_span6
#+end_row-fluid
#+end_container-fluid

#+begin_smaller
+ *Q: RLだけで 古典プランニングを解けるか?* (A: *不可*)

  *Q: RLだけで プランニングを高速化できるか?* (A: *不可*)

  *Q: プランニングの道具と適切に組み合わせれば?* */(A: 可)/*

  Lessons learned: */古典プランニングを甘く見るな/*
#+end_smaller
#+end_center


* IJCAI24

[[png:truncated-gaussian/title]]



#+begin_xlarge
#+begin_center
RL 嫌いなんで ... 教師あり学習!
#+end_center
#+end_xlarge

* Task: Learn the shortest path cost

[[png:truncated-gaussian/1b]]

** Task: Learn the shortest path cost

[[png:truncated-gaussian/1a]]

** Task: Learn the shortest path cost

[[png:truncated-gaussian/1]]

#+begin_larger
#+begin_center
+ *Q: Can we exploit the /admissibility/ of heuristics* in training?
#+end_center
#+end_larger

* Stop using (Mean) Square Errors!

[[png:truncated-gaussian/2j]]

** Stop using (Mean) Square Errors!

[[png:truncated-gaussian/2i]]

** Stop using (Mean) Square Errors!

[[png:truncated-gaussian/2h]]

** Stop using (Mean) Square Errors!

[[png:truncated-gaussian/2g]]

** Stop using (Mean) Square Errors!

[[png:truncated-gaussian/2f]]

** Stop using (Mean) Square Errors!

[[png:truncated-gaussian/2e]]

** Stop using (Mean) Square Errors!

[[png:truncated-gaussian/2d]]

** Stop using (Mean) Square Errors!

[[png:truncated-gaussian/2c]]

** Stop using (Mean) Square Errors!

[[png:truncated-gaussian/2b]]

** Stop using (Mean) Square Errors!

[[png:truncated-gaussian/2a]]

** Stop using (Mean) Square Errors!

[[png:truncated-gaussian/2]]

* 

[[png:truncated-gaussian/3c]]

** 

[[png:truncated-gaussian/3b]]

** 

[[png:truncated-gaussian/3a]]

** 

[[png:truncated-gaussian/3]]

* Thinking with Distributions                                      :noexport:

Is $\mathcal{N}(\mu,\sigma)$ the correct distribution for $h^*$?

[[png:truncated-gaussian/4]]

+ We know $h^*\ge 0$
+ We know $h^*\ge h$ : *admissible heuristics*
+ *Why the heck* do we assign */non-zero probability/* to $h^*< 0$?
+ i.e. $\mathcal{N}(\mu,\sigma)$ *ignores* our */expert knowledge/* on $h^*$
+ It is not the *correct* distribution

* Thinking with Distributions

Is $\mathcal{N}(\mu,\sigma)$ the correct distribution for $h^*$?

[[png:truncated-gaussian/4e]]

** Thinking with Distributions

Is $\mathcal{N}(\mu,\sigma)$ the correct distribution for $h^*$?

[[png:truncated-gaussian/4d]]

** Thinking with Distributions

Is $\mathcal{N}(\mu,\sigma)$ the correct distribution for $h^*$?

[[png:truncated-gaussian/4c]]

** Thinking with Distributions

Is $\mathcal{N}(\mu,\sigma)$ the correct distribution for $h^*$?

[[png:truncated-gaussian/4b]]

** Thinking with Distributions

Is $\mathcal{N}(\mu,\sigma)$ the correct distribution for $h^*$?

[[png:truncated-gaussian/4a]]

** Thinking with Distributions

Is $\mathcal{N}(\mu,\sigma)$ the correct distribution for $h^*$?

[[png:truncated-gaussian/4]]

* What is the correct distribution?

+ Follow the */Maximum Entropy Principle/* (Jaynes 1957):

  #+begin_quote
  + /Choose the distribution with the *largest entropy*/
  + /among those that satisfy the *expert knowledge / constraint*./
  #+end_quote

+
  #+begin_alignright
  #+begin_larger
  ↪ We know a lower bound $h\le h^*$ !

  *This is our expert knowledge!*
  #+end_larger
  #+end_alignright

* What is the max-ent distribution for our assumption?

[[png:truncated-gaussian/5c]]

** What is the max-ent distribution for our assumption?

[[png:truncated-gaussian/5b]]

** What is the max-ent distribution for our assumption?

[[png:truncated-gaussian/5a]]

** Results 

[[png:truncated-gaussian/6]]

* IJCAI 2024 : Conclusion

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
+ *We learn* $h^*$

  [[png:truncated-gaussian/1]]

#+end_span6
#+begin_span6
+ *Square error = Gaussian*

  [[png:truncated-gaussian/3]]
#+end_span6
#+end_row-fluid
#+begin_row-fluid
#+begin_span6
+ *Gaussian is a lie*

  [[png:truncated-gaussian/4]]
#+end_span6
#+begin_span6
+ *Max-ent: Truncated Gaussian*

  [[png:truncated-gaussian/5a]]
#+end_span6
#+end_row-fluid
#+end_container-fluid

Take-home message: *Whenever you see a square error, doubt it!*

* 理性的な実世界エージェントのアーキテクチャ

#+begin_container-fluid
#+begin_row-fluid
#+begin_span3
[[sgif:mars/yoda-hmph]]
#+end_span3
#+begin_span9
[[png:nesyarch/0b]]
#+end_span9
#+end_row-fluid
#+end_container-fluid

* 探索アルゴリズム


