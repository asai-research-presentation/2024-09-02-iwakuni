#+TITLE: Classical Planning in Deep Latent Space
#+include: "head.org"
#+LINK: img file:img/%s
#+LINK: png file:img/%s.png
#+LINK: jpg file:img/%s.jpg
#+LINK: svg file:img/%s.svg
#+LINK: gif file:img/%s.gif
#+LINK: spng file:img/static/%s.png
#+LINK: sjpg file:img/static/%s.jpg
#+html_head: <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:500,900">
#+html_head_extra:
#+LINK: ssvg file:img/static/%s.svg
#+LINK: sgif file:img/static/%s.gif

#+begin_outline-text-1
#+begin_center

　

#+begin_larger
Masataro Asai

(MIT-IBM Watson AI Lab, IBM Research, Cambridge)
#+end_larger

　

[[png:MIT-IBM]]

# [[spng:ibm-research]]

#+end_center

#+end_outline-text-1

* You found yourself on Mars, unexpected emergency...

[[png:mars/mars]]

* Two approaches to intelligence : Which is better?

#+begin_container-fluid
#+begin_row-fluid
#+begin_span3

[[png:mars/mars]]

#+end_span3
#+begin_span4
#+begin_center
Do you just follow what you *learned* before?
  
"Don't think, feel"?

[[sgif:yoda]]

/Reflex agent/

#+end_center
#+end_span4
#+begin_span5
+
  #+begin_center
  Or do you *think*, adjust, create and choose an appropriate behavior?
  
  [[sgif:mars/yoda-hmph]]

  _/Deliberative agent/_
  #+end_center
#+end_span5
#+end_row-fluid
#+end_container-fluid

#+begin_center
+ → _I wish to build a *logical, /deliberative/ agent*_

  that operates on the _raw input (e.g., visual input)_
#+end_center

* Classical Planners *solve 8-puzzles << .1sec.*

Symbolic systems excel at deliberation.

#+begin_container-fluid
#+begin_row-fluid
#+begin_span2

#+end_span2
#+begin_span4
[[png:8puzzle-standard]]
#+end_span4
#+begin_span4
[[png:8puzzle-standard-goal]]
#+end_span4
#+begin_span2
[[sgif:8puzzle]]
#+end_span2
#+end_row-fluid
#+end_container-fluid

/but only when we have a PDDL model./

#+begin_container-fluid
#+begin_row-fluid
#+begin_span12
#+begin_src scheme
(:action       move-up ...
 :precondition (and      (empty ?x ?y-old) ...)
 :effects      (and (not (empty ?x ?y-old))...))
#+end_src
#+end_span12
#+end_row-fluid
#+end_container-fluid

PDDL : Planning Domain Description Language

* They cannot solve an */Image-based/* 8-puzzle

#+begin_container-fluid
#+begin_row-fluid
#+begin_span8
[[sjpg:puzzle]]
#+end_span8
#+begin_span4
+ 
   #+begin_center
   *BECAUSE*

   *WE*

   *DO*

   *NOT*

   *HAVE*

   *A*

   #+begin_larger
   */PDDL/*

   */MODEL/!*
   #+end_larger
#+end_center
#+end_span4
#+end_row-fluid
#+end_container-fluid

+ *Latplan (AAAI18, ICAPS19, IJCAI20, Arxiv 21)* addresses this problem:

  */No Prior Explicit Knowledge/* (i.e. No Human Annotation)

  　 */No labels/symbols given/* : e.g. "9 tiles", "moving"

* Key problem Latplan solves: @@html:<br>@@ */Knowledge-Acquisition Bottleneck/*

# * We must *automate 2 processes*:

# * Knowledge-Acquisition Bottleneck:
# 
# #+begin_quote
# The *cost of human* involved for converting *real-world problems* into the inputs for
# domain-independent *symbolic* systems
# #+end_quote



#+begin_container-fluid
#+begin_row-fluid
#+begin_span4

#+begin_alignright
*Visual observations*
#+end_alignright

[[png:overview/1]]

#+end_span4
#+begin_span1
　

　

　

→

　
#+end_span1
#+begin_span7
#+begin_center
*PDDL Model*
#+end_center
#+begin_src scheme
(:action       move-up
 :precondition
 (and      (empty ?x ?y-old) ...)
 :effects
 (and (not (empty ?x ?y-old))...))
#+end_src

#+end_span7
#+end_row-fluid

#+begin_row-fluid
#+begin_span12
+ We must *automate 2 processes*:
#+end_span12
#+end_row-fluid
#+begin_row-fluid
#+begin_span6
+ *1. Symbol Grounding:*

  #+begin_center
  #+begin_larger
  */Symbols/ = words in PDDL*
  #+end_larger
  #+end_center
  
  #+begin_smaller
  | Types        | Examples                     |
  |--------------+------------------------------|
  | Objects      | *panel_7*, *x_0*, *y_0* ...  |
  | Predicates   | (*empty* ?x ?y)              |
  | Propositions | *p_28* = (empty x_0 y_0)     |
  | Actions      | (*slide-up* panel_7 x_0 y_1) |
  #+end_smaller
#+end_span6
#+begin_span6
+ *2. Action Model Acquisition:*
  
  #+begin_center
  #+begin_larger
  */Describe/ the*

  */transition rules/*

  *with symbols.*
  #+end_larger
  #+end_center
  
  　

  #+begin_center
  *When* /Empty(x, y_{old}) ∧ .../ ;

  *Then* /¬Empty(x,y_{old}) ∧/ ...
  #+end_center

#+end_span6
#+end_row-fluid
#+end_container-fluid

# #+begin_note
# The knowledge acquisition bottleneck: time for reassessment? : Cullen, J and Bryman, A Expert Syst. Vol 5 No 3 (August 1988) pp 216-225
# #+end_note

* Latplan system generates a PDDL (IJCAI20, Arxiv21)

[[png:15puzzle-with-pddl]]

#+begin_center
All symbols are anonymous & generated (=gensym=)

Note: I am not interested in *human symbols* at all

Requiring human symbols as input = parasitic (*)
#+end_center

#+begin_note
(*) Taddeo, Mariarosaria, and Luciano Floridi. "Solving the symbol grounding problem: a critical review of fifteen years of research." Journal of Experimental & Theoretical Artificial Intelligence 17.4 (2005): 419-445.
#+end_note

* Experimental Results

[[spng:experiment/init-goal]]

8-puzzle, 15-puzzle, Lights-Out, Twisted Lights-out, *Blocksworld*, Sokoban

** Success ratio (Arxiv 2021) : 40 problems / domain

[[png:success]]

** Success / Failure cases

[[spng:experiment/blocks-example]]

[[spng:experiment/other-examples]]

* How? *Generative modeling* + */Understanding the target formalism deeper/*

+ *Cube-Space AE* learns *PDDL-compatible effects*.
+ What is *PDDL compatibility* ?

# *Background Terminology:*
# 
# $z_{t} \rightarrow z_{t+1}$ is called a /progression/
# #+begin_alignright
# ($z_{t+1} \rightarrow z_{t}$ is called a /regression/)
# #+end_alignright

+ Action: $\text{Eat}(\text{food🍕})$ 
+ Precondition: $\lnot \text{full}() \land \text{have}(\text{food🍕})$
+ Effects: *Delete effects:* $\lnot\text{have}(\text{food🍕})$ : -- in the stomach now
+ Effects: *Add effects:　* $\text{full}()$

# + Action /eat(person, food)/
# + Precondition: ¬full(person) ∧ have(person, food)
# + Delete effect: ¬have(person, food)
# + Add effect: full(person)

# +
#   #+begin_src scheme
#   (:action eat :parameters (?person ?food)
#   #+end_src
# +
#   #+begin_src scheme
#   　 :precondition (and (not (full ?person))
#   　                   (have ?person ?food))
#   #+end_src
# +
#   #+begin_src scheme
#   　 :effects (and (not (have ?person ?food)) ; delete effects
#   　               (full ?person)))           ; add effects
#   #+end_src

+
  #+begin_quote
  _/Action application in PDDL:/_ $z_{t+1} = (z_t \setminus \text{del}(a)\ )\ \cup\ \text{add}(a)$
  #+end_quote

  Effects $\text{del}(a), \text{add}(a)$ *do not depend on $z_t$*.

+
  #+begin_quote
  */Naive AAE:/* $z_{t+1} = \text{apply}(z_t, a)$ : *No separation*
  #+end_quote

# +
#   #+begin_quote
#   _/PDDL effect:/_ $z_{t+1} = (z_t \ \setminus \ \text{del}(a)\ )\ \cup\ \text{add}(a)$
#   
#   */AAE's effect:/* $z_{t+1} = \text{apply}(z_t, a)$
#   #+end_quote
# 
#   *In PDDL, effects should be consistent for each action*.
# 
#   #+begin_alignright
#   *= Effects should be independent from $z_t$*
#   #+end_alignright


* We can model the dependency in a */graphical model/*

*In PDDL, effects must not depend on $z_t$*.

#+begin_center
→ A */random variable/* *e* independent from $z_t$.
#+end_center

[[png:space-ae/graphical-model-csae]]

　

+ A powerful mathematical framework:

  *Graphical model + Maximum-likelihood + Variational method* 

  #+begin_alignright
  → *End-to-end NN training* with a *statistically sound objective*.
  #+end_alignright

* Need an */appropriate/* model for */your/* target formalism

An example:
#+begin_center
Subsymbolic inputs → PDDL formalism → fast, PDDL solver
#+end_center

A proposal:
#+begin_center
+ *Nonlinear dynamics* → *linear latent control* → *fast, linear solver*
#+end_center

[[png:space-ae/graphical-model-style]]

#+begin_center
+ *Caution: It requires a /deep/ understanding of your formalism*

  *(e.g., PDDL, linear control).* Know what you are modeling!
#+end_center

* Extending the generative model (unpublished)

#+begin_container-fluid
#+begin_row-fluid
#+begin_span4
#+begin_center
+ Lifted actions,

  Parameters *x*
  
  [[png:space-ae/graphical-model-fosae]]

  Predicates, too.

  *Compatible with First Order Logic.*

#+end_center
#+end_span4
#+begin_span4
#+begin_center
+ Temporal actions,

  Action durations *d*

  [[png:space-ae/graphical-model-time]]

  *Compatible with LTL.*

#+end_center
#+end_span4
#+begin_span4
#+begin_center
+ Domain symbol *D*,

  Problem symbol *P*

  [[png:space-ae/graphical-model-domain]]

  Allows mixed-domain training?
#+end_center
#+end_span4
#+end_row-fluid
#+end_container-fluid

# + Discrete-Continuous
#
#  [[png:space-ae/graphical-model-style]]



* Conclusion

#+begin_container-fluid
#+begin_row-fluid
#+begin_span7
#+begin_center
+ *Goal: logical, rational agents*

  operating under *raw observations*
  
  [[sgif:mars/yoda-hmph]]
#+end_center
#+end_span7
#+begin_span5
#+begin_center
+ *Latplan*

  [[png:space-ae/3-1]]

  [[spng:experiment/blocks-example]]
#+end_center
#+end_span5
#+end_row-fluid
#+begin_row-fluid
#+begin_span7
#+begin_center
+ Each type of symbol requires

  *its own mechanism to learn*
  
  [[png:namespace/6]]
#+end_center
#+end_span7
#+begin_span5
#+begin_center
+ Generative models offer

  the *mathematical rigor*

  [[png:space-ae/graphical-model-csae]]
#+end_center
#+end_span5
#+end_row-fluid
#+end_container-fluid

#+begin_center
Masataro Asai, Hiroshi Kajino, Alex Fukunaga, Christian Muise:

*Classical Planning in Deep Latent Space.* Arxiv 2107.00110 -> JAIR
#+end_center

* Success / Failure cases

[[spng:experiment/blocks-example]]

[[spng:experiment/other-examples]]
* Why _/action symbol grounding/_ is necessary?

"designers always know the action space"? */Wrong!/*

Humans have a good understanding of low-level actuations...
  
#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
+
  #+begin_center
  Running
  #+end_center
  [[sjpg:triathlon/running]]
# sjpg:triathlon/bicycle
# sjpg:triathlon/swimming
#+end_span6
#+begin_span6
+ 
  #+begin_center
  Career Path
  #+end_center
  [[sjpg:triathlon/career]]

  #+begin_center
  Do you fully understand all of your opportunities?
  #+end_center
#+end_span6
#+end_row-fluid
#+begin_row-fluid
#+begin_span6
#+begin_center
+ *Low-level Control*
#+end_center
#+end_span6
#+begin_span6
#+begin_center
+ */High-level Action/*
#+end_center
#+end_span6
#+end_row-fluid
#+end_container-fluid

